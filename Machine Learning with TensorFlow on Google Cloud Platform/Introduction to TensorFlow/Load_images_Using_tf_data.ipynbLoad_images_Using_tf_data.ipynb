{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Load images Using tf.data.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "environment": {
      "name": "tf2-gpu.2-3.m65",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m65"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/QuanPhamAnh/Coursera_Capstone/blob/main/Machine%20Learning%20with%20TensorFlow%20on%20Google%20Cloud%20Platform/Introduction%20to%20TensorFlow/Load_images_Using_tf_data.ipynbLoad_images_Using_tf_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucMoYase6URl"
      },
      "source": [
        "# Loading Images Using tf.Data.Dataset\n",
        "\n",
        "**Learning Objectives**\n",
        "\n",
        "1. Retrieve Images using tf.keras.utils.get_file\n",
        "2. Load Images using Keras Pre-Processing\n",
        "3. Load Images using tf.Data.Dataset\n",
        "4. Understand basic Methods for Training\n",
        "\n",
        "## Introduction \n",
        "\n",
        "In this notebook, we load an image dataset using tf.data.  The dataset used in this example is distributed as directories of images, with one class of image per directory.\n",
        "\n",
        "\n",
        "Each learning objective will correspond to a **#TODO** in the [student lab notebook](https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/courses/machine_learning/deepdive2/introduction_to_tensorflow/solutions/load_images_tf.data.ipynb) -- try to complete that notebook first before reviewing this solution notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoQQiZDB6URn"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9G1ppg4ZB7Y"
      },
      "source": [
        "## Load necessary libraries \n",
        "We will start by importing the necessary libraries for this lab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIksPgtT8B6B"
      },
      "source": [
        "import IPython.display as display\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "print(\"TensorFlow version: \",tf.version.VERSION)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KT6CcaqgQewg"
      },
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wO0InzL66URu"
      },
      "source": [
        "### Retrieve the images\n",
        "\n",
        "Before you start any training, you will need a set of images to teach the network about the new classes you want to recognize. You can use an archive of creative-commons licensed flower photos from Google.\n",
        "\n",
        "Note: all images are licensed CC-BY, creators are listed in the `LICENSE.txt` file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rN-Pc6Zd6awg"
      },
      "source": [
        "import pathlib\n",
        "data_dir = tf.keras.utils.get_file(origin='https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
        "                                         fname='flower_photos', untar=True)\n",
        "data_dir = pathlib.Path(data_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFkFK74oO--g"
      },
      "source": [
        "After downloading (218MB), you should now have a copy of the flower photos available.\n",
        "\n",
        "The directory contains 5 sub-directories, one per class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhewYCxhXQBX"
      },
      "source": [
        "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
        "image_count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJ1HKKdR4A7c"
      },
      "source": [
        "CLASS_NAMES = np.array([item.name for item in data_dir.glob('*') if item.name != \"LICENSE.txt\"])\n",
        "CLASS_NAMES"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVxsk4OW61TY"
      },
      "source": [
        "Each directory contains images of that type of flower. Here are some roses:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crs7ZjEp60Ot"
      },
      "source": [
        "roses = list(data_dir.glob('dandelion/*'))\n",
        "\n",
        "for image_path in roses[:3]:\n",
        "    display.display(Image.open(str(image_path)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jobDTUs8Wxu"
      },
      "source": [
        "## Load using `keras.preprocessing`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehhW308g8soJ"
      },
      "source": [
        "A simple way to load images is to use `tf.keras.preprocessing`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQoXOxkiYo9T"
      },
      "source": [
        "**Lab Task #1:** load your images using tf.keras.preprocessing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syDdF_LWVrWE"
      },
      "source": [
        "# The 1./255 is to convert from uint8 to float32 in range [0,1].\n",
        "# TODO 1a\n",
        "# TODO -- Your code here.\n",
        "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAmtzsnjDNhB"
      },
      "source": [
        "Define some parameters for the loader:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zf695or-Flq"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "IMG_HEIGHT = 224\n",
        "IMG_WIDTH = 224\n",
        "STEPS_PER_EPOCH = np.ceil(image_count/BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pw94ajOOVrWI"
      },
      "source": [
        "train_data_gen = image_generator.flow_from_directory(directory=str(data_dir),\n",
        "                                                     batch_size=BATCH_SIZE,\n",
        "                                                     shuffle=True,\n",
        "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                     classes = list(CLASS_NAMES))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZgIZeXaDUsF"
      },
      "source": [
        "Inspect a batch for image processing:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLp0XVG_Vgi2"
      },
      "source": [
        "def show_batch(image_batch, label_batch):\n",
        "  plt.figure(figsize=(10,10))\n",
        "  for n in range(25):\n",
        "  # TODO 1b\n",
        "      ax = plt.subplot(5,5,n+1) # TODO -- Your code here.\n",
        "      plt.imshow(image_batch[n])\n",
        "      # TODO -- Your code here.\n",
        "      plt.title(CLASS_NAMES[label_batch[n]==1][0].title())\n",
        "      plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suh6Sjv68rY3"
      },
      "source": [
        "image_batch, label_batch = next(train_data_gen)\n",
        "show_batch(image_batch, label_batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxS1cLzM8mEp"
      },
      "source": [
        "## Load using `tf.data`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ylj9fgkamgWZ"
      },
      "source": [
        "The above `keras.preprocessing` method is convienient, but has three downsides: \n",
        "\n",
        "1. It's slow. See the performance section below.\n",
        "1. It lacks fine-grained control.\n",
        "1. It is not well integrated with the rest of TensorFlow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIG5CPaULegg"
      },
      "source": [
        "To load the files as a `tf.data.Dataset` first create a dataset of the file paths:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAkQp5uxoINu"
      },
      "source": [
        "list_ds = tf.data.Dataset.list_files(str(data_dir/'*/*'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coORvEH-NGwc"
      },
      "source": [
        "for f in list_ds.take(5):\n",
        "  print(f.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91CPfUUJ_8SZ"
      },
      "source": [
        "**Lab Task #2:** Write a short pure-tensorflow function that converts a file path to an `(img, label)` pair:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arSQzIey-4D4"
      },
      "source": [
        "def get_label(file_path):\n",
        "  # TODO 2a\n",
        "  # convert the path to a list of path components\n",
        "  # TODO -- Your code here.\n",
        "    parts = tf.strings.split(file_path, os.path.sep)\n",
        "  # The second to last is the class-directory\n",
        "  # TODO -- Your code here.\n",
        "    return parts[-2] == CLASS_NAMES"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGlq4IP4Aktb"
      },
      "source": [
        "def decode_img(img):\n",
        "  # TODO 2b\n",
        "  # convert the compressed string to a 3D uint8 tensor\n",
        "  # TODO -- Your code here.\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
        "  # TODO -- Your code here.\n",
        "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "  # resize the image to the desired size.\n",
        "    return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xhBRgvNqRRe"
      },
      "source": [
        "def process_path(file_path):\n",
        "    label = get_label(file_path)\n",
        "  # TODO 2c\n",
        "  # load the raw data from the file as a string\n",
        "    img = tf.io.read_file(file_path) \n",
        "  # TODO -- Your code here.\n",
        "    img = decode_img(img)\n",
        "    return img, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9a5GpsUOBx8"
      },
      "source": [
        "Use `Dataset.map` to create a dataset of `image, label` pairs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SDhbo8lOBQv"
      },
      "source": [
        "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
        "labeled_ds = list_ds.map(process_path, num_parallel_calls=AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxrl0lGdnpRz"
      },
      "source": [
        "for image, label in labeled_ds.take(1):\n",
        "  print(\"Image shape: \", image.numpy().shape)\n",
        "  print(\"Label: \", label.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYGCgJuR_9Qp"
      },
      "source": [
        "### Next Steps:  Basic methods for training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwZavzgsIytz"
      },
      "source": [
        "To train a model with this dataset you will want the data:\n",
        "\n",
        "* To be well shuffled.\n",
        "* To be batched.\n",
        "* Batches to be available as soon as possible.\n",
        "\n",
        "These features can be easily added using the `tf.data` api."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYB-gy0dYo9Z"
      },
      "source": [
        "**Lab Task #3:** Adding features using the tf.data api. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZmZJx8ePw_5"
      },
      "source": [
        "def prepare_for_training(ds, cache=True, shuffle_buffer_size=1000):\n",
        "  # This is a small dataset, only load it once, and keep it in memory.\n",
        "  # use `.cache(filename)` to cache preprocessing work for datasets that don't\n",
        "  # fit in memory.\n",
        "  # TODO 3a\n",
        "  if cache:\n",
        "    if isinstance(cache, str):\n",
        "      ds = ds.cache(cache)\n",
        "    else:\n",
        "      ds = ds.cache()\n",
        "\n",
        "  # TODO -- Your code here.\n",
        "\n",
        "  # Repeat forever\n",
        "  ds = ds.repeat()\n",
        "\n",
        "  ds = ds.batch(BATCH_SIZE)\n",
        "\n",
        "  # `prefetch` lets the dataset fetch batches in the background while the model\n",
        "  # is training.\n",
        "  ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "  return ds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YKnrfAeZV10"
      },
      "source": [
        "train_ds = prepare_for_training(labeled_ds)\n",
        "\n",
        "image_batch, label_batch = next(iter(train_ds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UN_Dnl72YNIj"
      },
      "source": [
        "show_batch(image_batch.numpy(), label_batch.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DS3tPwH5Yo9a"
      },
      "source": [
        "Copyright 2020 Google Inc.\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
        "http://www.apache.org/licenses/LICENSE-2.0\n",
        "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
      ]
    }
  ]
}